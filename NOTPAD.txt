59471574	2450000
59471613	159600000









59471571	
59471572	0
59471574	2450000
59471583	1170000
59471587	1170000
59471613	159600000
59471701	97970000
59471733	5960000


59471571	
59471572	0
59471574	2450000
59471583	1170000
59471587	1170000
59471613	159600000
59471701	2340000
59471733	1170000

('GST1808150000182GST1808150000180')






select channel_pay_type,disputes,order_id, trx_id, user_id, po.app_id, ai.app_name, product_name, order_amount_micros,default_amount_micros,pay_amount_micros,default_currency, currency_code, channel, os, po.create_time, po.status, notice_status, game_user_id, deliver_status, channel_id,country,city, po.test_flag, po.run_platform,  server_id,pay_done_time,cps_channel, discount_rate,po.pay_dollar_amount_micros,'USD' usd_currency from payment_order po left join app_info ai on ai.app_id=po.app_id where 1=1  and po.trx_id in  ('GST1808150000182') and po.create_time >= '2018-08-10 00:00:00'  and po.create_time <= '2018-08-16 23:59:59'  order by po.create_time desc limit 0,25





















SELECT sum(pay_dollar_amount_micros) sm,count(DISTINCT user_id) uc,a.client_id FROM payment_order a WHERE a.`status` = 1 AND a.client_id NOT IN (SELECT payment_order.client_id FROM payment_order INNER JOIN pay_black_list ON payment_order.client_id=pay_black_list.client_id) AND a.pay_done_time >= '2000-12-19 06:00:00' AND a.pay_done_time <= '2018-05-30 13:40:43' GROUP BY client_id HAVING uc > 1 AND sm > 1 ORDER BY uc DESC;



AND a.pay_done_time >= '2000-12-19 06:00:00' AND a.pay_done_time <= '2018-05-30 13:40:43'


SELECT
	sum(pay_dollar_amount_micros) sm,
	count(DISTINCT user_id) uc,
	a.client_id
FROM
	payment_order a
WHERE
	a.`status` = 1
AND a.client_id NOT IN (SELECT payment_order.client_id FROM payment_order INNER JOIN pay_black_list ON payment_order.client_id=pay_black_list.client_id)
AND a.pay_done_time >= '2000-12-19 06:00:00'
AND a.pay_done_time <= '2018-05-30 13:40:43'
GROUP BY
	client_id
HAVING
	uc > 1
AND sm > 1
ORDER BY
	uc DESC;

SELECT payment_order.client_id FROM payment_order INNER JOIN pay_black_list ON payment_order.client_id=pay_black_list.client_id

SELECT * FROM payment_order WHERE client_id='38290253eb6779141824d4745e854171'


select count(1) as paging_total_cnt from (SELECT sum(pay_dollar_amount_micros) sm,count(DISTINCT user_id) uc,a.client_id FROM payment_order a WHERE a.`status` = 1 AND a.client_id NOT IN (SELECT payment_order.client_id FROM payment_order INNER JOIN pay_black_list ON payment_order.client_id=pay_black_list.client_id) AND a.pay_done_time >= '2000-12-19 06:00:00' AND a.pay_done_time <= '2018-05-30 13:40:43' GROUP BY client_id HAVING uc > 1 AND sm > 1 ORDER BY uc DESC ) as paging_tem




SELECT DISTINCT
	user_id,
	(
		SELECT
			SUM(pay_dollar_amount_micros)
		FROM
			payment_order
		WHERE
			user_id = a.user_id
		AND client_id = a.client_id
		AND `status` = 1
	) as deviceAmount,
	(
		SELECT
			SUM(pay_dollar_amount_micros)
		FROM
			payment_order
		WHERE
			user_id = a.user_id
		AND app_id = 'f7f9a9d18da611e5a0be000d3a906774'
		AND `status` = 1
	) as appAmount,
	(
		SELECT
			count(*)
		FROM
			payment_order
		WHERE
			user_id = a.user_id
		AND client_id = a.client_id
		AND `status` = 1
	) as count
FROM
	payment_order a
WHERE
	client_id = '38290253eb6779141824d4745e854171'
AND `status` = 1;









**************************************************************************
【Resin安装&卸载】

解压 gz

cd resin文件夹

../configure		此文件已备份（使用已备份文件）(在此文件中配置resin的install目录，并且此目录要重新赋予resin用户和组)


make


sudo make install		（此命令后会在/etc下创建resin配置相关的文件夹）


替换上一步操作生成的/etc/resin文件夹中的resin.xml和resin.properties文件，此两份文件已确认备份



(此处应确认install的文件夹已经重新赋予resin用户和组)
若没有：
执行
chown  resin  /var/resin/ 
chgrp  resin /var/resin/ 




将/etc/resin/resin.properties  setuid_uer及setuid_group改为上面创建的resin，如若使用备份的文件，则此操作已经完成，可以跳过



原先resin.sh  + start / stop 的启动停止命令 改为 resinctl + start / stop







---------------------------------------------------------------------------------------------------------------------
 String location = "G:\\pageFile";
        File tempdir = new File(location);
        if (!tempdir.exists()) {
            tempdir.mkdirs();
        }

        try {
            InputStream inputStream = pageFile.getInputStream();
            FileOutputStream outputStream = new FileOutputStream(new File("G:\\pageFile", pageFile.getName()));
            IOUtils.copy(inputStream,outputStream);
            outputStream.flush();
            outputStream.close();
            inputStream.close();
            return ResponseData.success().data("G:\\pageFile"+pageFile.getName());
        }catch (IOException ex) {
            log.error("uploadImg occurred error:{}", ex.getMessage(), ex);
        }




<div class="switch switch-small" id="mySwitch"><input id="preCheck" type="checkbox" /></div>

UPSERT


UPSERT INTO V2_H5_NEW_USER_PAYMENT (CREATETIME,LP,H5_CHANNELID,SUBCHANNEL,COUNTRY,REGIST_TERMINAL,NEW_USER_COUNT,
USER_PAYMENT_COUNT_1_WEEK,USER_PAYMENT_AMOUNT_1_WEEK,
USER_PAYMENT_COUNT_2_WEEK,USER_PAYMENT_AMOUNT_2_WEEK,
USER_PAYMENT_COUNT_3_WEEK,USER_PAYMENT_AMOUNT_3_WEEK,
USER_PAYMENT_COUNT_4_WEEK,USER_PAYMENT_AMOUNT_4_WEEK,
USER_PAYMENT_COUNT_5_WEEK,USER_PAYMENT_AMOUNT_5_WEEK,
USER_PAYMENT_COUNT_6_WEEK,USER_PAYMENT_AMOUNT_6_WEEK,
USER_PAYMENT_COUNT_7_WEEK,USER_PAYMENT_AMOUNT_7_WEEK,
USER_PAYMENT_COUNT_8_WEEK,USER_PAYMENT_AMOUNT_8_WEEK,
USER_PAYMENT_COUNT_9_WEEK,USER_PAYMENT_AMOUNT_9_WEEK,
USER_PAYMENT_COUNT_10_WEEK,USER_PAYMENT_AMOUNT_10_WEEK,
USER_PAYMENT_COUNT_11_WEEK,USER_PAYMENT_AMOUNT_11_WEEK,
USER_PAYMENT_COUNT_12_WEEK,USER_PAYMENT_AMOUNT_12_WEEK,
USER_PAYMENT_COUNT_13_WEEK,USER_PAYMENT_AMOUNT_13_WEEK,
USER_PAYMENT_COUNT_14_WEEK,USER_PAYMENT_AMOUNT_14_WEEK,
USER_PAYMENT_COUNT_15_WEEK,USER_PAYMENT_AMOUNT_15_WEEK,
USER_PAYMENT_COUNT_16_WEEK,USER_PAYMENT_AMOUNT_16_WEEK) 
VALUES
('1532044800000','1','2','google','US','PC',100,
89,890,
102,630,
102,630,
102,630,
102,630,
102,630,
102,630,
102,630,
102,630,
102,630,
102,630,
102,630,
102,630,
102,630,
102,630,
102,630
);


<a onclick="continuePay.exchange()"><i class="fa fa-exchange" aria-hidden="true"></i></a>
TEST

select                                     
'ALL' AS H5_CHANNELID,      
'ALL' AS LP,
'ALL' AS SUBCHANNEL,
'ALL' AS COUNTRY,
'ALL' AS REGIST_TERMINAL,
CREATETIME         sum(TO_NUMBER(NEW_USER_COUNT)) as NEW_USER_COUNT,         sum(TO_NUMBER(USER_PAYMENT_COUNT_1_WEEK)) as USER_PAYMENT_COUNT_1_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_1_WEEK)) as USER_PAYMENT_AMOUNT_1_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_2_WEEK)) as USER_PAYMENT_COUNT_2_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_2_WEEK)) as USER_PAYMENT_AMOUNT_2_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_3_WEEK)) as USER_PAYMENT_COUNT_3_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_3_WEEK)) as USER_PAYMENT_AMOUNT_3_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_4_WEEK)) as USER_PAYMENT_COUNT_4_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_4_WEEK)) as USER_PAYMENT_AMOUNT_4_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_5_WEEK)) as USER_PAYMENT_COUNT_5_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_5_WEEK)) as USER_PAYMENT_AMOUNT_5_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_6_WEEK)) as USER_PAYMENT_COUNT_6_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_6_WEEK)) as USER_PAYMENT_AMOUNT_6_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_7_WEEK)) as USER_PAYMENT_COUNT_7_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_7_WEEK)) as USER_PAYMENT_AMOUNT_7_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_8_WEEK)) as USER_PAYMENT_COUNT_8_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_8_WEEK)) as USER_PAYMENT_AMOUNT_8_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_9_WEEK)) as USER_PAYMENT_COUNT_9_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_9_WEEK)) as USER_PAYMENT_AMOUNT_9_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_10_WEEK)) as USER_PAYMENT_COUNT_10_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_10_WEEK)) as USER_PAYMENT_AMOUNT_10_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_11_WEEK)) as USER_PAYMENT_COUNT_11_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_11_WEEK)) as USER_PAYMENT_AMOUNT_11_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_12_WEEK)) as USER_PAYMENT_COUNT_12_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_12_WEEK)) as USER_PAYMENT_AMOUNT_12_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_13_WEEK)) as USER_PAYMENT_COUNT_13_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_13_WEEK)) as USER_PAYMENT_AMOUNT_13_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_14_WEEK)) as USER_PAYMENT_COUNT_14_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_14_WEEK)) as USER_PAYMENT_AMOUNT_14_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_15_WEEK)) as USER_PAYMENT_COUNT_15_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_15_WEEK)) as USER_PAYMENT_AMOUNT_15_WEEK,         sum(TO_NUMBER(USER_PAYMENT_COUNT_16_WEEK)) as USER_PAYMENT_COUNT_16_WEEK,         sum(TO_NUMBER(USER_PAYMENT_AMOUNT_16_WEEK)) as USER_PAYMENT_AMOUNT_16_WEEK               from         V2_H5_NEW_USER_PAYMENT         where            CREATETIME>=? AND CREATETIME<=?





mysql表增加字段语句

alter table admin_config add transactor varchar(10) not Null;



******
MODE SQL SUCCESS

select sum(NEW_USER_COUNT) as NEW_USER_COUNT from V2_H5_NEW_USER_PAYMENT GROUP BY H5_CHANNELID

select CREATETIME,LP,H5_CHANNELID,SUBCHANNEL,COUNTRY, sum(NEW_USER_COUNT) as NEW_USER_COUNT from V2_H5_NEW_USER_PAYMENT GROUP BY H5_CHANNELID



****



select
CREATETIME,LP,H5_CHANNELID,SUBCHANNEL,COUNTRY,
        sum( (NEW_USER_COUNT)) as NEW_USER_COUNT,
        sum( (USER_PAYMENT_COUNT_1_WEEK)) as USER_PAYMENT_COUNT_1_WEEK,
        sum( (USER_PAYMENT_AMOUNT_1_WEEK)) as USER_PAYMENT_AMOUNT_1_WEEK,
        sum( (USER_PAYMENT_COUNT_2_WEEK)) as USER_PAYMENT_COUNT_2_WEEK,
        sum( (USER_PAYMENT_AMOUNT_2_WEEK)) as USER_PAYMENT_AMOUNT_2_WEEK,
        sum( (USER_PAYMENT_COUNT_3_WEEK)) as USER_PAYMENT_COUNT_3_WEEK,
        sum( (USER_PAYMENT_AMOUNT_3_WEEK)) as USER_PAYMENT_AMOUNT_3_WEEK,
        sum( (USER_PAYMENT_COUNT_4_WEEK)) as USER_PAYMENT_COUNT_4_WEEK,
        sum( (USER_PAYMENT_AMOUNT_4_WEEK)) as USER_PAYMENT_AMOUNT_4_WEEK,
        sum( (USER_PAYMENT_COUNT_5_WEEK)) as USER_PAYMENT_COUNT_5_WEEK,
        sum( (USER_PAYMENT_AMOUNT_5_WEEK)) as USER_PAYMENT_AMOUNT_5_WEEK,
        sum( (USER_PAYMENT_COUNT_6_WEEK)) as USER_PAYMENT_COUNT_6_WEEK,
        sum( (USER_PAYMENT_AMOUNT_6_WEEK)) as USER_PAYMENT_AMOUNT_6_WEEK,
        sum( (USER_PAYMENT_COUNT_7_WEEK)) as USER_PAYMENT_COUNT_7_WEEK,
        sum( (USER_PAYMENT_AMOUNT_7_WEEK)) as USER_PAYMENT_AMOUNT_7_WEEK,
        sum( (USER_PAYMENT_COUNT_8_WEEK)) as USER_PAYMENT_COUNT_8_WEEK,
        sum( (USER_PAYMENT_AMOUNT_8_WEEK)) as USER_PAYMENT_AMOUNT_8_WEEK,
        sum( (USER_PAYMENT_COUNT_9_WEEK)) as USER_PAYMENT_COUNT_9_WEEK,
        sum( (USER_PAYMENT_AMOUNT_9_WEEK)) as USER_PAYMENT_AMOUNT_9_WEEK,
        sum( (USER_PAYMENT_COUNT_10_WEEK)) as USER_PAYMENT_COUNT_10_WEEK,
        sum( (USER_PAYMENT_AMOUNT_10_WEEK)) as USER_PAYMENT_AMOUNT_10_WEEK,
        sum( (USER_PAYMENT_COUNT_11_WEEK)) as USER_PAYMENT_COUNT_11_WEEK,
        sum( (USER_PAYMENT_AMOUNT_11_WEEK)) as USER_PAYMENT_AMOUNT_11_WEEK,
        sum( (USER_PAYMENT_COUNT_12_WEEK)) as USER_PAYMENT_COUNT_12_WEEK,
        sum( (USER_PAYMENT_AMOUNT_12_WEEK)) as USER_PAYMENT_AMOUNT_12_WEEK,
        sum( (USER_PAYMENT_COUNT_13_WEEK)) as USER_PAYMENT_COUNT_13_WEEK,
        sum( (USER_PAYMENT_AMOUNT_13_WEEK)) as USER_PAYMENT_AMOUNT_13_WEEK,
        sum( (USER_PAYMENT_COUNT_14_WEEK)) as USER_PAYMENT_COUNT_14_WEEK,
        sum( (USER_PAYMENT_AMOUNT_14_WEEK)) as USER_PAYMENT_AMOUNT_14_WEEK,
        sum( (USER_PAYMENT_COUNT_15_WEEK)) as USER_PAYMENT_COUNT_15_WEEK,
        sum( (USER_PAYMENT_AMOUNT_15_WEEK)) as USER_PAYMENT_AMOUNT_15_WEEK,
        sum( (USER_PAYMENT_COUNT_16_WEEK)) as USER_PAYMENT_COUNT_16_WEEK,
        sum( (USER_PAYMENT_AMOUNT_16_WEEK)) as USER_PAYMENT_AMOUNT_16_WEEK
        from V2_H5_NEW_USER_PAYMENT
        GROUP BY CREATETIME,LP,H5_CHANNELID,SUBCHANNEL,COUNTRY,REGIST_TERMINAL



select
CREATETIME,LP,H5_CHANNELID,SUBCHANNEL,COUNTRY,
        sum( (NEW_USER_COUNT)) as NEW_USER_COUNT,
        sum( (USER_PAYMENT_COUNT_1_WEEK)) as USER_PAYMENT_COUNT_1_WEEK,
        sum( (USER_PAYMENT_AMOUNT_1_WEEK)) as USER_PAYMENT_AMOUNT_1_WEEK,
        sum( (USER_PAYMENT_COUNT_2_WEEK)) as USER_PAYMENT_COUNT_2_WEEK,
        sum( (USER_PAYMENT_AMOUNT_2_WEEK)) as USER_PAYMENT_AMOUNT_2_WEEK,
        sum( (USER_PAYMENT_COUNT_3_WEEK)) as USER_PAYMENT_COUNT_3_WEEK,
        sum( (USER_PAYMENT_AMOUNT_3_WEEK)) as USER_PAYMENT_AMOUNT_3_WEEK,
        sum( (USER_PAYMENT_COUNT_4_WEEK)) as USER_PAYMENT_COUNT_4_WEEK,
        sum( (USER_PAYMENT_AMOUNT_4_WEEK)) as USER_PAYMENT_AMOUNT_4_WEEK,
        sum( (USER_PAYMENT_COUNT_5_WEEK)) as USER_PAYMENT_COUNT_5_WEEK,
        sum( (USER_PAYMENT_AMOUNT_5_WEEK)) as USER_PAYMENT_AMOUNT_5_WEEK,
        sum( (USER_PAYMENT_COUNT_6_WEEK)) as USER_PAYMENT_COUNT_6_WEEK,
        sum( (USER_PAYMENT_AMOUNT_6_WEEK)) as USER_PAYMENT_AMOUNT_6_WEEK,
        sum( (USER_PAYMENT_COUNT_7_WEEK)) as USER_PAYMENT_COUNT_7_WEEK,
        sum( (USER_PAYMENT_AMOUNT_7_WEEK)) as USER_PAYMENT_AMOUNT_7_WEEK,
        sum( (USER_PAYMENT_COUNT_8_WEEK)) as USER_PAYMENT_COUNT_8_WEEK,
        sum( (USER_PAYMENT_AMOUNT_8_WEEK)) as USER_PAYMENT_AMOUNT_8_WEEK,
        sum( (USER_PAYMENT_COUNT_9_WEEK)) as USER_PAYMENT_COUNT_9_WEEK,
        sum( (USER_PAYMENT_AMOUNT_9_WEEK)) as USER_PAYMENT_AMOUNT_9_WEEK,
        sum( (USER_PAYMENT_COUNT_10_WEEK)) as USER_PAYMENT_COUNT_10_WEEK,
        sum( (USER_PAYMENT_AMOUNT_10_WEEK)) as USER_PAYMENT_AMOUNT_10_WEEK,
        sum( (USER_PAYMENT_COUNT_11_WEEK)) as USER_PAYMENT_COUNT_11_WEEK,
        sum( (USER_PAYMENT_AMOUNT_11_WEEK)) as USER_PAYMENT_AMOUNT_11_WEEK,
        sum( (USER_PAYMENT_COUNT_12_WEEK)) as USER_PAYMENT_COUNT_12_WEEK,
        sum( (USER_PAYMENT_AMOUNT_12_WEEK)) as USER_PAYMENT_AMOUNT_12_WEEK,
        sum( (USER_PAYMENT_COUNT_13_WEEK)) as USER_PAYMENT_COUNT_13_WEEK,
        sum( (USER_PAYMENT_AMOUNT_13_WEEK)) as USER_PAYMENT_AMOUNT_13_WEEK,
        sum( (USER_PAYMENT_COUNT_14_WEEK)) as USER_PAYMENT_COUNT_14_WEEK,
        sum( (USER_PAYMENT_AMOUNT_14_WEEK)) as USER_PAYMENT_AMOUNT_14_WEEK,
        sum( (USER_PAYMENT_COUNT_15_WEEK)) as USER_PAYMENT_COUNT_15_WEEK,
        sum( (USER_PAYMENT_AMOUNT_15_WEEK)) as USER_PAYMENT_AMOUNT_15_WEEK,
        sum( (USER_PAYMENT_COUNT_16_WEEK)) as USER_PAYMENT_COUNT_16_WEEK,
        sum( (USER_PAYMENT_AMOUNT_16_WEEK)) as USER_PAYMENT_AMOUNT_16_WEEK
        from V2_H5_NEW_USER_PAYMENT
        GROUP BY CREATETIME,LP,H5_CHANNELID,SUBCHANNEL,COUNTRY,REGIST_TERMINAL













【源端165】
1.安装inotify-tools （由于官网只找到3.13，所以165这里安装的inotify-tools版本为3.13）
[root@inotify-master tools]# tar zxf inotify-tools-3.14.tar.gz
[root@inotify-master tools]# cd inotify-tools-3.14
[root@inotify-master inotify-tools-3.14]# ./configure --prefix=/usr/local/inotify-3.14 #配置inotify,并指定安装路径为/usr/local/inotify-3.14
................................
[root@inotify-master inotify-tools-3.14]# make && make install


2.inotify-master配置密码文件
[root@inotify-master ~]# echo "leesir" >/etc/rsync.password
[root@inotify-master ~]# cat /etc/rsync.password
leesir   #注意：这里只要写密码
[root@inotify-master ~]# chmod 600 /etc/rsync.password
[root@inotify-master ~]# ll /etc/rsync.password
-rw------- 1 root root 7 4月  22 14:32 /etc/rsync.password

3.编写监控脚本并加载到后台执行
************************************************************************************
[root@inotify-master scripts]# cat inotify.sh
#!/bin/bash
#para
host01=172.16.100.161  #inotify-slave的ip地址
src=/backup/        #本地监控的目录
dst=backup         #inotify-slave的rsync服务的模块名
user=rsync_backup      #inotify-slave的rsync服务的虚拟用户
rsync_passfile=/etc/rsync.password   #本地调用rsync服务的密码文件
inotify_home=/usr/local/inotify-3.14    #inotify的安装目录
#judge
if [ ! -e "$src" ] \
|| [ ! -e "${rsync_passfile}" ] \
|| [ ! -e "${inotify_home}/bin/inotifywait" ] \
|| [ ! -e "/usr/bin/rsync" ];
then
echo "Check File and Folder"
exit 9
fi
${inotify_home}/bin/inotifywait -mrq --timefmt '%d/%m/%y %H:%M' --format '%T %w%f' -e close_write,delete,create,attrib $src \
| while read file
do
#  rsync -avzP --delete --timeout=100 --password-file=${rsync_passfile} $src $user@$host01::$dst >/dev/null 2>&1
cd $src && rsync -aruz -R --delete ./  --timeout=100 $user@$host01::$dst --password-file=${rsync_passfile} >/dev/null 2>&1
done
exit 0
************************************************************************************

4.后台启动
sh inotify.sh &

5.同步文件测试
OVER~




【被同步端161】
1.安装rsync,经检查161上已经安装，此步骤跳过。
2.新建rsync用户及模块目录并更改其用户组
[root@inotify-slave mail]# useradd rsync -s /sbin/nologin  -M #添加rsync用户
[root@inotify-slave mail]# grep rsync /etc/passwd
rsync:x:2004:2004::/home/rsync:/sbin/nologin
[root@inotify-slave mail]# mkdir /backup   #创建rsync daemon工作模式的模块目录 --------》》》》》》 被同步文件夹必须更改该目录的用户组为使用的虚拟用户
[root@inotify-slave mail]# ll -d /backup/
drwxr-xr-x. 2 root root 4096 4月  22 14:13 /backup/
[root@inotify-slave mail]# chown rsync.rsync /backup/   #更改模块目录的用户组
[root@inotify-slave mail]# ll -d /backup/
drwxr-xr-x. 2 rsync rsync 4096 4月  22 14:13 /backup/

3.编写rsync daemon配置文件/etc/rsyncd.conf
[root@inotify-slave /]# cat /etc/rsyncd.conf
##rsyncd.conf start##
#工作中指定用户(需要指定用户)
uid = rsync
gid = rsync
#相当于黑洞.出错定位
use chroot = no
#有多少个客户端同时传文件
max connections = 200
#超时时间
timeout = 300
#进程号文件
pid file = /var/run/rsyncd.pid
#日志文件
lock file = /var/run/rsync.lock
#日志文件
log file = /var/log/rsyncd.log
#模块开始
#这个模块对应的是推送目录
#模块名称随便起
[backup]
#需要同步的目录
path = /backup/
#表示出现错误忽略错误
ignore errors
#表示网络权限可写(本地控制真正可写)
read only = false
#这里设置IP或让不让同步
list = false
#指定允许的网段
hosts allow = 192.168.1.0/24
#拒绝链接的地址，下面表示不拒绝拒绝所有链接。
hosts deny = 0.0.0.0/32
#不要动的东西(默认情况)
#虚拟用户
auth users = rsync_backup
#虚拟用户的密码文件
secrets file = /etc/rsync.password
#配置文件的结尾
#rsync_config_______________end

4.配置虚拟用户的密码文件
[root@inotify-slave /]# echo "rsync_backup:leesir" >/etc/rsync.password
[root@inotify-slave /]# cat /etc/rsync.password
rsync_backup:leesir   #注：rsync_backup为虚拟用户，leesir为这个虚拟用户的密码
[root@inotify-slave /]# chmod 600 /etc/rsync.password #为密码文件提权，增加安全性
[root@inotify-slave /]# ll /etc/rsync.password
-rw-------. 1 root root 20 4月  22 14:20 /etc/rsync.password

5.启动rsync 服务
[root@inotify-slave /]# rsync --daemon   #启动rsync服务
[root@inotify-slave /]# ps -ef |grep rsync
root     14871     1  0 14:24 ?        00:00:00 rsync --daemon
root     14873 14788  0 14:24 pts/0    00:00:00 grep rsync
[root@inotify-slave /]# netstat -lnutp |grep rsync
tcp        0      0 0.0.0.0:873                 0.0.0.0:*                   LISTEN      14871/rsync
tcp        0      0 :::873                      :::*                        LISTEN






********************************************************************************



Hbase适合存储大量的对关系运算要求低的NOSQL数据，受Hbase 设计上的限制不能直接使用原生的PAI执行在关系数据库中普遍使用的条件判断和聚合等操作。Hbase很优秀，一些团队寻求在Hbase之上提供一种更面向普通开发人员的操作方式，Apache Phoenix即是。
Phoenix 基于Hbase给面向业务的开发人员提供了以标准SQL的方式对Hbase进行查询操作，并支持标准SQL中大部分特性:条件运算,分组，分页，等高级查询语法。


HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。

Hadoop是一个由Apache基金会所开发的分布式系统基础架构。
用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。
[1]  Hadoop实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。HDFS有高容错性的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。
Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，则MapReduce为海量的数据提供了计算。 [2] 




SELECT CREATETIME,SUM(REGISTRATION_PAGE_PV) as REGISTRATION_PAGE_PV,SUM(REGISTRATION_SUBMIT_COUNT) AS REGISTRATION_SUBMIT_COUNT,SUM(REGISTRATION_COUNT) AS REGISTRATION_COUNT FROM V2_H5_REGISTRATION GROUP BY CREATETIME

INSERT INTO PressCtrlH (H5_CHANNELID) VALUES ('6');

UPSERT INTO V2_H5_REGISTRATION (CREATETIME,LP,H5_CHANNELID,SUBCHANNEL,GUEST_COUNT.REGISTRATION_PAGE_UV,REGISTRATION_PAGE_PV,REGISTRATION_SUBMIT_COUNT,REGISTRATION_COUNT) VALUES ('1530259758000','1','1','1',100,100,100,100,100)

UPSERT INTO V2_H5_REGISTRATION (CREATETIME,LP,H5_CHANNELID,SUBCHANNEL,GUEST_COUNT,REGISTRATION_PAGE_UV,REGISTRATION_PAGE_PV,REGISTRATION_SUBMIT_COUNT,REGISTRATION_COUNT) VALUES ('1530094950000','1','2','1',100,100,100,100,100)

SELECT * FROM V2_H5_REGISTRATION

UPSERT INTO V2_H5_REGISTRATION (CREATETIME,GUEST_COUNT,REGISTRATION_PAGE_UV) VALUES ('1530202080000',200,200)

UPSERT INTO V2_H5_REGISTRATION (CREATETIME,H5_CHANNELID,GUEST_COUNT,REGISTRATION_PAGE_UV) VALUES ('1530202080000','_ALL',200,200)

//错误SQL
SELECT CREATETIME,SUM(REGISTRATION_PAGE_PV) as REGISTRATION_PAGE_PV,SUM(REGISTRATION_SUBMIT_COUNT) AS REGISTRATION_SUBMIT_COUNT,SUM(REGISTRATION_COUNT) AS REGISTRATION_COUNT FROM V2_H5_REGISTRATION GROUP BY CREATETIME AND (CREATETIME>='1529712000000' AND CREATETIME<='1530316799000') AND H5_CHANNELID !='_ALL'  GROUP BY CREATETIME


SELECT CREATETIME,SUM(REGISTRATION_PAGE_PV) as REGISTRATION_PAGE_PV,SUM(REGISTRATION_SUBMIT_COUNT) AS REGISTRATION_SUBMIT_COUNT,SUM(REGISTRATION_COUNT) AS REGISTRATION_COUNT FROM V2_H5_REGISTRATION WHERE 1=1  AND (CREATETIME>='1529712000000' AND CREATETIME<='1530316799000') AND H5_CHANNELID !='_ALL'  GROUP BY CREATETIME





2018-7-2
*****************************【FastDFS+Nginx安装】*****************************************

系统：CentOS

fastdfs-master-V5.05.zip         
fastdfs-nginx-module-master.zip  
libfastcommon-master.zip         
nginx-1.10.0.tar.gz              
ngx_cache_purge-2.3.tar.gz       
openssl-1.0.1t         


1.yum install make cmake gcc gcc-c++
2.wget https://github.com/downloads/libevent/libevent/libevent-1.4.14b-stable.tar.gz
3. wget https://codeload.github.com/happyfish100/fastdfs/tar.gz/V5.05
	tar -zxvf FastDFS_v5.08.tar.gz
	cd FastDFS

	./make.sh
	./make.sh install

	
启动Tracker 
/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start

启动stronger
/usr/bin/fdfs_trackerd /etc/fdfs/storage.conf start

【安装Nginx】...
befor{
	
	yum -y install gcc automake autoconf libtool make
	yum install gcc gcc-c++
	2.安装PCRE库 wget    https://netix.dl.sourceforge.net/project/pcre/pcre/8.40/pcre-8.40.tar.gz

	3.安装zlib库 wget http://zlib.net/zlib-1.2.11.tar.gz
	4.安装ssl wget https://www.openssl.org/source/openssl-1.0.1t.tar.gz

}

nginx model配置 ./configure --add-module=/usr/local/nginx/fastdfs-nginx-module-master/src


【问题总结】
配置完成后上传文件失败：{
	pkill -9 fdfs

	/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf

	/usr/bin/fdfs_storaged /etc/fdfs/storage.conf
}
上传成功后访问404：{
	


}





【CSDN文档】

FastDFS安装全过程记录
1、安装准备
HA虚拟IP：192.168.1.208 

HA软件：Keepalived 

操作系统：CentOS 7 

用户：root 

数据目录：/data/fastdfs

安装包： 

fastdfs-master-V5.05.zip：FastDFS源码 

libfastcommon-master.zip：（从 FastDFS 和 FastDHT 中提取出来的公共 C 函数库） 

fastdfs-nginx-module-master.zip：storage节点http服务nginx模块 

nginx-1.10.0.tar.gz：Nginx安装包 

ngx_cache_purge-2.3.tar.gz：Nginx图片缓存清除模块 

获取安装包的方式： 

1> 从这里下载打包好的所有安装包：http://download.csdn.net/detail/xyang81/9667493 

2> 从作者github官网挨个下载fastdfs源码及其依赖库：https://github.com/happyfish100 和 Nginx缓存清除模块：https://github.com/FRiCKLE/ngx_cache_purge
开始前，先将所有安装包下载到各个节点的/usr/local/src目录中。

1> 本文称节点IP最后一段就代表某个节点，如：192.168.1.206，文中提到206节点，就代表192.168.1.206。 

2> 本文称tracker或跟踪服务器是同一个意思 

3> 本文称storage或存储服务器是同一个意思

2、开始安装
1.安装所需依赖包
shell> yum install make cmake gcc gcc-c++
2.安装 FastDFS三步走
[root@localhost ~]# cd /usr/local/src
[root@localhost src]# ls
fastdfs-master-V5.05.zip         
fastdfs-nginx-module-master.zip  
libfastcommon-master.zip         
nginx-1.10.0.tar.gz              
ngx_cache_purge-2.3.tar.gz       
openssl-1.0.1t                   
2.1 安装 libfastcommon
解压 libfastcommon，命令：

[root@localhost src]# unzip libfastcommon-master.zip
[root@localhost src]# cd libfastcommon-master
[root@localhost libfastcommon-master]# ./make.sh
[root@localhost libfastcommon-master]# ./make.sh install
执行以上4步，安装完毕，即完成第一步。

2.2 安装 FastDFS
解压 libfastcommon，命令：

[root@localhost libfastcommon-master]# cd ..
[root@localhost src]# ls
fastdfs-master-V5.05.zip         openssl-1.0.1t.tar.gz
fastdfs-nginx-module-master.zip  pcre-8.39
libfastcommon-master             pcre-8.39.tar.gz
libfastcommon-master.zip         zlib-1.2.8
nginx-1.10.0.tar.gz              zlib-1.2.8.tar.gz
ngx_cache_purge-2.3.tar.gz       zlib-1.2.8.tar.gz.1
openssl-1.0.1t
[root@localhost src]# unzip fastdfs-master-V5.05.zip
[root@localhost src]# cd fastdfs-master-V5.05
-bash: cd: fastdfs-master-V5.05: 没有那个文件或目录
[root@localhost src]# ls
fastdfs-master                   openssl-1.0.1t
fastdfs-master-V5.05.zip         openssl-1.0.1t.tar.gz
fastdfs-nginx-module-master.zip  pcre-8.39
libfastcommon-master             pcre-8.39.tar.gz
libfastcommon-master.zip         zlib-1.2.8
nginx-1.10.0.tar.gz              zlib-1.2.8.tar.gz
ngx_cache_purge-2.3.tar.gz       zlib-1.2.8.tar.gz.1
[root@localhost src]# cd fastdfs-master
[root@localhost fastdfs-master]# ./make.sh
[root@localhost fastdfs-master]# ./make.sh install
执行以上几步，
显示：

[root@localhost fastdfs-master]# ./make.sh install
cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O -DDEBUG_FLAG        -c -o ../common/fdfs_global.o ../common/fdfs_global.c  -I../    common -I/usr/include/fastcommon
cc -Wall -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE -g -O -DDEBUG_FLAG        -c -o tracker_proto.o tracker_proto.c  -I../common -I/usr/  include/fastcommon
...
tracker_client.h storage_client.h storage_client1.h client_func.h       client_global.h fdfs_client.h /usr/include/fastdfs
if [ ! -f /etc/fdfs/client.conf.sample ]; then cp -f ../conf/       client.conf /etc/fdfs/client.conf.sample; fi
即安装完毕！

3 配置 Tracker 服务
上述安装成功后，在/etc/目录下会有一个fdfs的目录，进入它。会看到三个.sample后缀的文件，这是作者给我们的示例文件，我们需要把其中的tracker.conf.sample文件改为tracker.conf配置文件并修改它。看命令：

[root@localhost fastdfs-master]# cd /etc/fdfs
[root@localhost fdfs]# ls
client.conf.sample  storage.conf.sample  tracker.conf.sample
---
[root@localhost fdfs]# cp tracker.conf.sample tracker.conf
[root@localhost fdfs]# vim tracker.conf
打开tracker.conf文件，只需要找到你只需要该这两个参数就可以了。

# the base path to store data and log files
base_path=/data/fastdfs
# HTTP port on this tracker server
http.server_port=80
当然前提是你要有或先创建了/data/fastdfs目录。port=22122这个端口参数不建议修改，除非你已经占用它了。
修改完成保存并退出 vim ，这时候我们可以使用/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start来启动 Tracker服务，但是这个命令不够优雅，怎么做呢？使用ln -s 建立软链接：

ln -s /usr/bin/fdfs_trackerd /usr/local/bin
ln -s /usr/bin/stop.sh /usr/local/bin
ln -s /usr/bin/restart.sh /usr/local/bin
这时候我们就可以使用service fdfs_trackerd start来优雅地启动 Tracker服务了，是不是比刚才带目录的命令好记太多了（懒是社会生产力）。你也可以启动过服务看一下端口是否在监听，命令：

启动服务：service fdfs_trackerd start
查看监听：netstat -unltp|grep fdfs
启动命令如下：

[root@localhost fdfs]# mkdir /data
[root@localhost fdfs]# mkdir /data/fastdfs
[root@localhost fdfs]# /usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start
看到22122端口正常被监听后，这时候就算 Tracker服务安装成功啦！

[root@localhost fdfs]# netstat -unltp | grep fdfs
tcp        0      0 0.0.0.0:22122           0.0.0.0:*
LISTEN      5895/fdfs_trackerd  
4、配置 Storage 服务
现在开始配置 Storage 服务，由于我这是单机器测试，你把 Storage 服务放在多台服务器也是可以的，它有 Group(组)的概念，同一组内服务器互备同步，这里不再演示。直接开始配置，依然是进入/etc/fdfs的目录操作，首先进入它。会看到三个.sample后缀的文件，我们需要把其中的storage.conf.sample文件改为storage.conf配置文件并修改它。还看命令：

cp storage.conf.sample storage.conf
vim storage.conf
指令操作：

[root@localhost fdfs]# cd /etc/fdfs
[root@localhost fdfs]# cp storage.conf.sample storage.conf
[root@localhost fdfs]# vim storage.conf
    
打开storage.conf文件后，找到这两个参数进行修改：

# the base path to store data and log files
base_path=/data/fastdfs/storage
# store_path#, based 0, if store_path0 not exists, it's value is base_path
# the paths must be exist
store_path0=/data/fastdfs/storage
#store_path1=/home/yuqing/fastdfs2
# tracker_server can ocur more than once, and tracker_server format is
#  "host:port", host can be hostname or ip address
tracker_server=192.168.198.129:22122
当然你的/data/fastdfs目录下要有storage文件夹，没有就创建一个，不然会报错的，日志以及文件都会在这个下面，启动时候会自动生成许多文件夹。stroage的port=23000这个端口参数也不建议修改，默认就好，除非你已经占用它了。
修改完成保存并退出 vim ，这时候我们依然想优雅地启动 Storage服务，带目录的命令不够优雅，这里还是使用ln -s 建立软链接：

ln -s /usr/bin/fdfs_storaged /usr/local/bin
执行命令启动服务：

service fdfs_storaged start
出现了一个大大的error啦！！！要仔细看，错误提示是找不到文件夹，这就好办了嘛。创建一个文件夹再次启动看看。

[root@localhost fdfs]# /usr/bin/fdfs_storaged start
[2017-02-08 14:48:00] ERROR - file: shared_func.c, line: 968, /etc/fdfs/start is not a regular file
[2017-02-08 14:48:00] ERROR - file: process_ctrl.c, line: 230, load conf file "start" fail, ret code: 22
这次启动成功，没有错误了。查看一下监听：

netstat -unltp|grep fdfs
监听如下：

[root@localhost fdfs]# netstat -unltp|grep fdfs
tcp        0      0 0.0.0.0:22122           0.0.0.0:*               LISTEN      5895/fdfs_trackerd  
tcp        0      0 0.0.0.0:23000           0.0.0.0:*               LISTEN      6001/fdfs_storaged  
很好，22122 和 23000端口都在监听了，这个时候你去/data/fastdfs/storage文件夹下看的话，会出现一大堆文件夹，而且进去还有一大堆，哈哈，这就是存放文件的啦！

5服务监听测试
我们安装配置并启动了 Tracker 和 Storage 服务，也没有报错了。那他俩是不是在通信呢？我们可以监视一下：

/usr/bin/fdfs_monitor /etc/fdfs/storage.conf
看到我横线处ACTIVE这样就 ok 啦！

    [root@localhost fdfs]# /usr/bin/fdfs_monitor /etc/fdfs/storage.conf
[2017-02-08 14:51:16] DEBUG - base_path=/data/fastdfs/storage, connect_timeout=30, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=600s, use_storage_id=0, storage server id count: 0

server_count=1, server_index=0

tracker server is 192.168.160.130:22122

group count: 1

Group 1:
group name = group1
disk total space = 17878 MB
disk free space = 10198 MB
trunk free space = 0 MB
storage server count = 1
active server count = 1
storage server port = 23000
storage HTTP port = 8888
store path count = 1
subdir count per path = 256
current write server index = 0
current trunk file id = 0

Storage 1:
    id = 192.168.160.130
    ip_addr = 192.168.160.130 (localhost.localdomain)  ACTIVE
    http domain = 
    version = 5.08
    join time = 2017-02-08 14:49:53
    up time = 2017-02-08 14:49:53
其实这个时候你就可以进行上传测试了，但可能会下载不了，

6 安装 Nginx 和 fastdfs-nginx-module
解压 fastdfs-nginx-module ，记着这时候别用tar解压了，因为是 .zip 文件，正确命令：

unzip master.zip
1）配置 nginx 安装，加入fastdfs-nginx-module模块
这是和普通 Nginx 安装不一样的地方，因为加载了模块。
若nginx未安装，根据相关教程进行安装，若已安装，查看已安装的nginx的版本，找到源码的存放位置，然后配置fastdfs-nginx-module模块

[root@localhost src]# cd /home/roo/下载/nginx-1.11.6
[root@localhost nginx-1.11.6]# ./configure --add-module=/usr/local/src/fastdfs-nginx-module-master/src/
checking for OS
 + Linux 3.10.0-327.36.3.el7.x86_64 x86_64
checking for C compiler ... found
[root@localhost nginx-1.11.6]# make && make install
这时候，我们可以看一下 Nginx 下安装成功的版本及模块，命令：

/usr/local/nginx/sbin/nginx -V
配置 fastdfs-nginx-module 和 Nginx
1.配置mod-fastdfs.conf，并拷贝到/etc/fdfs文件目录下。
cd /usr/local/src/fastdfs-nginx-module-master/src/
vim mod_fastdfs.conf
cp mod_fastdfs.conf /etc/fdfs
修改mod-fastdfs.conf配置只需要修改我标注的这三个地方就行了，其他不需要也不建议改变。

# FastDFS tracker_server can ocur more than once, and tracker_server format is
#  "host:port", host can be hostname or ip address
# valid only when load_fdfs_parameters_from_tracker is true
tracker_server=192.168.198.129:22122
# if the url / uri including the group name
# set to false when uri like /M00/00/00/xxx
# set to true when uri like ${group_name}/M00/00/00/xxx, such as group1/M00/xxx
# default value is false
url_have_group_name = true
    # store_path#, based 0, if store_path0 not exists, it's value is base_path
# the paths must be exist
# must same as storage.conf
store_path0=/data/fastdfs/storage
#store_path1=/home/yuqing/fastdfs1

接着我们需要把fastdfs-5.05下面的配置中还没有存在/etc/fdfs中的拷贝进去

cd /usr/local/src/fastdfs-5.05/conf
cp anti-steal.jpg http.conf mime.types /etc/fdfs/
2.配置 Nginx。编辑nginx.conf文件：
cd /usr/local/nginx/conf
vi nginx.conf
在配置文件中加入：

location /group1/M00 {
    root /data/fastdfs/storage/;
    ngx_fastdfs_module;
}
由于我们配置了group1/M00的访问，我们需要建立一个group1文件夹，并建立M00到data的软链接。

mkdir /data/fastdfs/storage/data/group1
ln -s /data/fastdfs/storage/data /data/fastdfs/storage/data/group1/M00
启动 Nginx ，会打印出fastdfs模块的pid，看看日志是否报错，正常不会报错的

/usr/local/nginx/sbin/nginx
打开浏览器，访问一下发现并不能访问，也并没有报错，但显示如下画面。糟糕了，怎么办？对了，我好像没关闭防火墙。

开放80端口访问权限。在iptables中加入重启就行，或者你直接关闭防火墙，本地测试环境可以这么干，但到线上万万不能关闭防火墙的。

vi /etc/sysconfig/iptables
-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT
重启防火墙，使设置生效：

service iptables restart
再次刷新浏览器，可以看到如下画面，说明我们 Nginx 结合 fastdfs-nginx-module 模块安装并配置成功啦！

我最后说一下怎么在已经安装过 Nginx 的服务器上安装配置 fastdfs-nginx-module 模块？ 因为，一般我们线上服务器都是已经安装过 Nginx 的，所以这个时候，我们就直接进入 Nginx 的存放目录，进行配置后编译，就不需要执行最后安装make install这一步了，接着重启就行了。

上传测试
完成上面的步骤后，我们已经安装配置完成了全部工作，接下来就是测试了。因为执行文件全部在/usr/bin目录下，我们切换到这里，并新建一个test.txt文件，随便写一点什么，我写了This is a test file. by:mafly这句话在里边。然后测试上传：

cd /usr/bin
vim test.txt
fdfs_test /etc/fdfs/client.conf upload test.txt
很不幸，并没有成功，报错了。

ERROR - file: shared_func.c, line: 960, open file /etc/fdfs/client.conf fail, errno: 2, error info: No such file or directory
ERROR - file: ../client/client_func.c, line: 402, load conf file "/etc/fdfs/client.conf" fail, ret code: 2
一般什么事情第一次都不是很顺利，这很正常，通过错误提示我看到，好像没有找到client.conf这个文件，现在想起来的确没有配置这个文件，那我们现在去配置一下图中的两个参数：

cd /etc/fdfs
cp client.conf.sample client.conf
vim client.conf
怎么还依然报错阿？？？

upload file fail, error no: 2, error info: No such file or directory
哈哈，你是不是测试上传命令中要上传的test.txt文件路径有问题，嗯，那我改一下命令：

/usr/bin/fdfs_test /etc/fdfs/client.conf upload /usr/bin/test.txt
成功啦！！！ 返回文件信息及上传后的文件 HTTP 地址，你打开浏览器访问一下试试

7.总结一下
接下来其实还有更多关于文件的工作，比如防盗链、图片切图、视频处理等等。

1.防盗链的常用方案
>1.加token验证
>2.将FastDFS返回的地址，转化为该地址的映射，通过中间件来进行转换访问
2.关于Storage集群分组存储方式
1.Storage server会连接集群中所有的Tracker server，定时向他们报告自己的状态，包括磁盘剩余空间、文件同步状况、文件上传下载次数等统计信息。

2.storage集群由一个或多个组构成，集群存储总容量为集群中所有组的存储容量之和。一个组由一台或多台存储服务器组成，组内的Storage server之间是平等关系，不同组的Storage server之间不会相互通信，同组内的Storage server之间会相互连接进行文件同步，从而保证同组内每个storage上的文件完全一致的。一个组的存储容量为该组内存储服务器容量最小的那个，由此可见组内存储服务器的软硬件配置最好是一致的。采用分组存储方式的好处是灵活、可控性较强。比如上传文件时，可以由客户端直接指定上传到的组也可以由tracker进行调度选择。一个分组的存储服务器访问压力较大时，可以在该组增加存储服务器来扩充服务能力（纵向扩容）。当系统容量不足时，可以增加组来扩充存储容量（横向扩容）。

3.关于上传的文件备注信息NameValuePair(源文件细息)的存储
原文件信息的存储：

>1.在上传文件时，写入FastDfs中的该文件NameValuePair[]中，但此方式只能根据文件查看文件的备注信息，FastDfs没有提供逆向查询的方式；
>2.在关系型数据库创建一张表，用于存储该group下的所有文件信息，此方式可以解决第一种方式的逆向查询问题，同时可以存储FastDfs的文件信息；
8.FastDfs常见异常汇总
1. 上传文件失败，返回错误码28，这是怎么回事？
返回错误码28，表示磁盘空间不足。注意FastDFS中有
预留空间的概念，在tracker.conf中设置，配置项为
：reserved_storage_space，缺省值为4GB，即预留
4GB的空间。请酌情设置reserved_storage_space这个
参数，比如可以设置为磁盘总空间的20%左右。

2. nginx扩展模块，不能正常显示图片的问题
在配置文件/etc/fdfs/mod_fastdfs.conf中，缺省的
设置是这样的：http.need_find_content_type=false
这个参数在nginx中需要设置为true，apache中应该设置为false

3. 如何删除无效的storage server？
可以使用fdfs_monitor来删除。命令行如下：
/usr/local/bin/fdfs_monitor delete
例如：
/usr/local/bin/fdfs_monitor
/etc/fdfs/client.conf delete group1
192.168.0.100
注意：如果被删除的storage server的状态是ACTIVE
，也就是该storage server还在线上服务的情况下，
是无法删除掉的。

4. 执行fdfs_test或fdfs_test1上传文件时，服务器
返回错误号2
错误号2表示没有ACTIVE状态的storage server。可以
执行fdfs_monitor查看服务器状态。




